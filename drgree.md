# 关键性能考量
## 并行度
**RDD的逻辑表示其实是一个对象集合**。  
即在物理执行期间，RDD会被分为一系列的分区，每个分区都是整个数据的子集。当Spark调度并运行
任务时，Spark会为每个分区中的数据创建出一个任务。该任务在默认情况下会需要集群中的一个计算核心来执行。Spark也会针对RDD直接自动推断出合适
的并行度，这对于大多数用例来说已经足够了。  
例:从HDFS上读数据的输入RDD会为数据在HDFS上的每个文件区块创建一个分区。从数据混洗后的RDD派生下来的RDD则会采用与其父RDD相同的并行度。  
